{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7UQ1QvQq/dvVKaGyNB9lv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-wessler/nbm-verification/blob/main/get_nbm_aws_streamline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3\n",
        "!pip install pygrib\n",
        "\n",
        "import os, boto3, pygrib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from botocore import UNSIGNED\n",
        "from botocore.client import Config"
      ],
      "metadata": {
        "id": "ZP6Vq6urQJst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Globals\n",
        "aws_bucket = 'noaa-nbm-grib2-pds'\n",
        "\n",
        "# Where to place the grib file (subdirs can be added in local) (not used)\n",
        "# output_dir = './'\n",
        "\n",
        "# Which grib variables do each element correlate with\n",
        "element_var = {'qpf':'APCP',\n",
        "                  'maxt':'TMP',\n",
        "                  'mint':'TMP'}\n",
        "\n",
        "# Which grib levels do each element correlate with\n",
        "element_lev = {'qpf':'surface',\n",
        "               'maxt':'2 m above ground',\n",
        "               'mint':'2 m above ground'}\n",
        "\n",
        "# If a grib message contains any of these, exclude\n",
        "excludes = ['ens std dev', '% lev']"
      ],
      "metadata": {
        "id": "mlF-5hehQNbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ro8LqKJLQB4r"
      },
      "outputs": [],
      "source": [
        "def fetch_grib_from_AWS(**req):\n",
        "\n",
        "    output_file = f'{req[\"yyyymmdd\"]}.t{req[\"hh\"]:02d}z.fhr{req[\"fhr\"]:03d}.{req[\"var\"]}.grib2'\n",
        "\n",
        "    if os.path.isfile(output_file):\n",
        "        return output_file\n",
        "\n",
        "    else:\n",
        "        for nbm_set in req['nbm_set']:\n",
        "\n",
        "            bucket_dir = f'blend.{req[\"yyyymmdd\"]}/{req[\"hh\"]:02d}/{nbm_set}/'\n",
        "\n",
        "            grib_file = f'{bucket_dir}blend.t{req[\"hh\"]:02d}z.'+\\\n",
        "                        f'{nbm_set}.f{req[\"fhr\"]:03d}.{req[\"nbm_area\"]}.grib2'\n",
        "\n",
        "            index_file = f'{grib_file}.idx'\n",
        "\n",
        "            client = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
        "\n",
        "            index_data_raw = client.get_object(\n",
        "                Bucket=aws_bucket, Key=index_file)['Body'].read().decode().split('\\n')\n",
        "\n",
        "            cols = ['num', 'byte', 'date', 'var', 'level',\n",
        "                'forecast', 'fthresh', 'ftype', '']\n",
        "\n",
        "            index_data = pd.DataFrame([item.split(':') for item in index_data_raw],\n",
        "                            columns=cols if nbm_set == 'core' else cols[:-1])\n",
        "\n",
        "            # Clean up any ghost indicies, set the index\n",
        "            index_data = index_data[index_data['num'] != '']\n",
        "            index_data['num'] = index_data['num'].astype(int)\n",
        "            index_data = index_data.set_index('num')\n",
        "\n",
        "            # Allow byte ranging to '' (EOF)\n",
        "            index_data.loc[index_data.shape[0]+1] = ['']*index_data.shape[1]\n",
        "\n",
        "            index_subset = index_data[\n",
        "                ((index_data['var'] == req['var']) &\n",
        "                (index_data['level'] == req['level']))]\n",
        "\n",
        "            # byte start >> byte range\n",
        "            for i in index_subset.index:\n",
        "                index_subset.loc[i]['byte'] = (\n",
        "                    index_data.loc[i, 'byte'],\n",
        "                    index_data.loc[int(i)+1, 'byte'])\n",
        "\n",
        "            # Filter out excluded vars\n",
        "            for ex in excludes:\n",
        "                mask = np.column_stack([index_subset[col].str.contains(ex, na=False)\n",
        "                                        for col in index_subset])\n",
        "\n",
        "                index_subset = index_subset.loc[~mask.any(axis=1)]\n",
        "\n",
        "            # Fetch the data by byte range, write from stream\n",
        "            for index, item in index_subset.iterrows():\n",
        "                byte_range = f\"bytes={item['byte'][0]}-{item['byte'][1]}\"\n",
        "\n",
        "                output_bytes = client.get_object(\n",
        "                    Bucket=aws_bucket, Key=grib_file, Range=byte_range)\n",
        "\n",
        "                with open(output_file, 'ab') as wfp:\n",
        "                    for chunk in output_bytes['Body'].iter_chunks(chunk_size=4096):\n",
        "                        wfp.write(chunk)\n",
        "\n",
        "    client.close()\n",
        "    return output_file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "element = input('Desired element? (QPF/MaxT/MinT)').lower()\n",
        "\n",
        "request_args = {\n",
        "    'yyyymmdd':input('Desired init date (YYYYMMDD)? '),\n",
        "    'hh':int(input('Desired init hour int(HH)? ')),\n",
        "    'fhr':int(input('Desired forecast hour/lead time int(HHH)?')),\n",
        "    'nbm_set':['core', 'qmd'] if element == 'qpf' else ['core'],\n",
        "    'nbm_area':'co',\n",
        "    'var':element_var[element],\n",
        "    'level':element_lev[element]}\n",
        "\n",
        "grib_output_file = fetch_grib_from_AWS(**request_args)\n",
        "\n",
        "for item in pygrib.open(grib_output_file).read():\n",
        "    print(item)"
      ],
      "metadata": {
        "id": "vtgrpivgQTNb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}